# -*- coding: utf-8 -*-
"""Prediksi Tingkat Obesitas2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1nMXkFm5pSr8W14Gg0KeSIsxtfLFxdlQm
"""

# Judul aplikasi
st.title("Aplikasi Prediksi Tingkat Obesitas")

# Deskripsi aplikasi
st.markdown("""
Aplikasi ini digunakan untuk memprediksi tingkat obesitas berdasarkan data yang dimasukkan.
Silakan isi informasi berikut:
""")

# Input data
st.header("Input Data")
age = st.number_input("Usia (tahun)", min_value=0, max_value=120)
gender = st.selectbox("Jenis Kelamin", ["Male", "Female"])
height = st.number_input("Tinggi Badan (m)", min_value=0.5, max_value=2.5)
weight = st.number_input("Berat Badan (kg)", min_value=30, max_value=250)
family_history = st.selectbox("Apakah ada riwayat keluarga yang mengalami kelebihan berat badan?", ["Ya", "Tidak"])
FAVC = st.selectbox("Sering mengonsumsi makanan tinggi kalori?", ["Ya", "Tidak"])
FCVC = st.number_input("Frekuensi mengonsumsi sayuran (dalam sekali makan)", min_value=1, max_value=5)
NCP = st.number_input("Jumlah makan besar dalam sehari", min_value=1, max_value=10)
SMOKE = st.selectbox("Apakah Anda merokok?", ["Ya", "Tidak"])
CH2O = st.number_input("Jumlah air yang Anda minum setiap hari (liter)", min_value=0.5, max_value=5.0)
FAF = st.number_input("Frekuensi aktivitas fisik (dalam sekali seminggu)", min_value=0, max_value=7)

# Tombol untuk memprediksi
if st.button("Prediksi"):
    # Proses prediksi (placeholder)
    # Model prediksi yang sudah dilatih harus di-load di sini
    # prediction = model.predict([[age, gender, height, weight, ...]])

    # Contoh prediksi
    prediction = np.random.choice(["Normal Weight", "Overweight Level I", "Obesity Type I", "Obesity Type II", "Obesity Type III"])

    st.success(f"Hasil Prediksi: {prediction}")

# Visualisasi
st.header("Visualisasi Data")
st.markdown("""
Berikut adalah visualisasi data yang dapat membantu Anda memahami distribusi tingkat obesitas.
""")

# Contoh visualisasi distribusi target
data = pd.read_csv('ObesityDataSet.csv')
plt.figure(figsize=(10, 5))
sns.countplot(x='NObeyesdad', data=data)
plt.title('Distribusi Tingkat Obesitas')
st.pyplot(plt)

# Menampilkan deskripsi data
st.header("Deskripsi Data")
st.write(data.describe())

# Kesimpulan
st.header("Kesimpulan")
st.markdown("""
Aplikasi ini memberikan estimasi tingkat obesitas berdasarkan input yang diberikan.
Silakan masukkan data Anda untuk melihat hasil prediksi.
""")

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from imblearn.over_sampling import SMOTE
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.model_selection import GridSearchCV
import streamlit as st

# Commented out IPython magic to ensure Python compatibility.
# %pip install streamlit

"""1.EDA"""

# Load dataset
data = pd.read_csv('ObesityDataSet.csv')

# Tampilkan beberapa baris pertama
print(data.head())

# Informasi umum
print(data.info())

# Deskripsi data
print(data.describe())

# Jumlah baris dan kolom
print(f"Jumlah baris: {data.shape[0]}, Jumlah kolom: {data.shape[1]}")

"""Visualisai Data"""

# Visualisasi distribusi target
sns.countplot(x='NObeyesdad', data=data)
plt.title('Distribusi Tingkat Obesitas')
plt.show()

"""Cek Missing Values, Unique Value, Data Duplikat, Keseimbangan Data, dan Outlier"""

# Cek missing values
print(data.isnull().sum())

# Cek unique values
print(data.nunique())

# Cek data duplikat
print(f"Jumlah duplikat: {data.duplicated().sum()}")

# Visualisasi outlier dengan boxplot
plt.figure(figsize=(12, 6))
sns.boxplot(data=data, orient='h')
plt.title('Boxplot untuk Deteksi Outlier')
plt.show()

"""2. Preprocessing Data

Tangani Missing Values, Error, Duplikasi, dan Outlier
"""

# Menghapus duplikat
data.drop_duplicates(inplace=True)

# Mengisi missing values dengan median untuk kolom numerik saja
numeric_cols = data.select_dtypes(include=['number']).columns
data[numeric_cols] = data[numeric_cols].fillna(data[numeric_cols].median())

# Menghapus outlier jika perlu (contoh pada kolom 'Weight')
Q1 = data['Weight'].quantile(0.25)
Q3 = data['Weight'].quantile(0.75)
IQR = Q3 - Q1
data = data[(data['Weight'] >= (Q1 - 1.5 * IQR)) & (data['Weight'] <= (Q3 + 1.5 * IQR))]



""" Ubah Data Kategori Menjadi Numerik"""

# Menggunakan pd.get_dummies untuk konversi kategori menjadi numerik
data = pd.get_dummies(data, drop_first=True)

"""Tentukan Apakah Semua Feature Perlu Digunakan"""

# Tentukan fitur yang akan digunakan
target_columns = [col for col in data.columns if col.startswith('NObeyesdad_')]
features = data.drop(columns=target_columns)
target = data[target_columns]

"""Atasi Ketidakseimbangan Kelas Data"""

from imblearn.over_sampling import SMOTE

smote = SMOTE()
target_labels = target.idxmax(axis=1)
features_resampled, target_resampled = smote.fit_resample(features, target_labels)

"""Normalisasi atau Standarisasi Data"""

scaler = StandardScaler()
features_scaled = scaler.fit_transform(features_resampled)

"""3. Pemodelan dan Evaluasi

Pemodelan Menggunakan Minimal 3 Algoritma Klasifikasi
"""

# Split data
X_train, X_test, y_train, y_test = train_test_split(features_scaled, target_resampled, test_size=0.2, random_state=42)

# Inisialisasi model
models = {
    'Logistic Regression': LogisticRegression(),
    'Random Forest': RandomForestClassifier(),
    'SVM': SVC()
}

# Melatih dan mengevaluasi model
for name, model in models.items():
    model.fit(X_train, y_train)
    predictions = model.predict(X_test)
    print(f"Model: {name}")
    print(classification_report(y_test, predictions))
    print(confusion_matrix(y_test, predictions))

"""Visualisasi Perbandingan Performa Antar Model"""

# Visualisasi perbandingan performa
results = {name: model.score(X_test, y_test) for name, model in models.items()}
sns.barplot(x=list(results.keys()), y=list(results.values()))
plt.title('Perbandingan Akurasi Model')
plt.ylabel('Akurasi')
plt.show()

"""4. Hyperparameter Tuning

Optimasi Hyperparameter Tuning
"""

param_grid = {
    'n_estimators': [50, 100],
    'max_depth': [None, 10, 20],
}

grid_search = GridSearchCV(RandomForestClassifier(), param_grid, cv=5)
grid_search.fit(X_train, y_train)

# Model terbaik
best_model = grid_search.best_estimator_
print(f"Best parameters: {grid_search.best_params_}")

"""Latih Ulang Model dengan Parameter Terbaik dan Evaluasi"""

best_model.fit(X_train, y_train)
predictions = best_model.predict(X_test)
print(classification_report(y_test, predictions))

# Akurasi sebelum tuning
accuracies_before = {
    'Logistic Regression': 0.78,  # Contoh nilai
    'Random Forest': 0.85,        # Contoh nilai
    'SVM': 0.80                    # Contoh nilai
}

# Visualisasi performa sebelum optimasi
plt.figure(figsize=(10, 5))
sns.barplot(x=list(accuracies_before.keys()), y=list(accuracies_before.values()))
plt.title('Akurasi Model Sebelum Hyperparameter Tuning')
plt.ylabel('Akurasi')
plt.ylim(0, 1)
plt.show()

# Akurasi setelah tuning
accuracies_after = {
    'Best Random Forest': best_model.score(X_test, y_test)  # Menggunakan model terbaik
}

# Tambahkan akurasi model lain jika ada
# accuracies_after['Model Nama'] = model.score(X_test, y_test)

# Visualisasi performa setelah optimasi
plt.figure(figsize=(10, 5))
sns.barplot(x=list(accuracies_after.keys()), y=list(accuracies_after.values()))
plt.title('Akurasi Model Setelah Hyperparameter Tuning')
plt.ylabel('Akurasi')
plt.ylim(0, 1)
plt.show()

# Gabungkan akurasi sebelum dan sesudah tuning
combined_accuracies = {**accuracies_before, **accuracies_after}

plt.figure(figsize=(12, 6))
sns.barplot(x=list(combined_accuracies.keys()), y=list(combined_accuracies.values()))
plt.title('Perbandingan Akurasi Model Sebelum dan Setelah Hyperparameter Tuning')
plt.ylabel('Akurasi')
plt.ylim(0, 1)
plt.xticks(rotation=45)
plt.show()